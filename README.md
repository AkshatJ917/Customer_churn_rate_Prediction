# ğŸ”„ Customer Churn Rate Prediction  

An end-to-end **Machine Learning project** to predict customer churn using the **Online Retail II dataset** (1M+ transactions).

---

## ğŸ“– Overview  

Customer churn prediction helps businesses identify at-risk customers early and take proactive retention actions.  

This project builds a **complete ML pipeline** â€” from raw transactional data to a fully optimized model achieving **91.6% Recall**.

---

## ğŸ”„ Project Workflow  

ğŸ§¹ **Data Cleaning**  
â†“  
ğŸ§  **RFM Feature Engineering**  
â†“  
âš–ï¸ **SMOTE Class Balancing**  
â†“  
ğŸ¤– **Model Training & Comparison**  
â†“  
ğŸ¯ **Threshold Tuning**  
â†“  
ğŸ”§ **GridSearchCV Hyperparameter Optimization**  
â†“  
âœ… **Final Tuned XGBoost Model**

---

## ğŸ¤– Model Comparison  

| Model                  | Recall | F1-Score | ROC-AUC |
|------------------------|--------|----------|----------|
| Logistic Regression    | 0.841  | 0.751    | 0.791    |
| Random Forest          | 0.689  | 0.687    | 0.737    |
| â­ **Tuned XGBoost**   | **0.916** | 0.747 | 0.793 |

ğŸ† **Winner: Tuned XGBoost @ Threshold 0.40**  
Catches **9 out of 10** at-risk customers!

---

## ğŸ“Š Key Insights from the Final Model  

After training, tuning, and evaluating the final **Tuned XGBoost model**, here are the major takeaways:

### ğŸ¯ High Recall is the Priority  
With a **Recall of 91.6%**, the model successfully identifies the vast majority of customers likely to churn â€” minimizing missed intervention opportunities.

### ğŸ’¡ Threshold Tuning Was a Game Changer  
Lowering the decision threshold from **0.50 â†’ 0.40** boosted Recall from **79.9% â†’ 91.6%**.  
This proves that **threshold optimization can sometimes be more impactful than hyperparameter tuning alone**.

### ğŸ” Frequency & Monetary Are the Strongest Signals  
Customers who purchase less frequently and spend lower amounts are significantly more likely to churn.

### âš ï¸ Recency Causes Data Leakage  
Since churn was defined as *â€œno purchase in 90 daysâ€*, the **Recency** feature was intentionally excluded to prevent data leakage.

### âš–ï¸ SMOTE Prevented Class Bias  
By balancing the dataset close to a **50/50 churn split**, SMOTE ensured the model did not over-predict the majority class.

### ğŸ”§ GridSearchCV Provided Marginal but Consistent Gains  
Hyperparameter tuning improved:
- **ROC-AUC:** 0.790 â†’ 0.793  
- **Recall:** 90.5% â†’ 91.6%  

These improvements confirm the model is **well-optimized and stable**.

---

## ğŸ“¥ Dataset & Requirements  

- Download the **Online Retail II Dataset** from the attached files.  
- Make sure to review the **requirements.txt** before running the project.
